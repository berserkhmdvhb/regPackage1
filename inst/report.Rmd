---
title: "Car Insurance Claims Dataset Classification - Report"
author: "Hamed Vaheb"
#1date: "09 Jan 2021"
output:
  html_document:
    number_sections: yes
    toc: yes
    code_folding: hide
    theme: readable
    highlight: haddock
  pdf_document:
    toc: yes
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(regPackage1)
library(dplyr)
library(janitor)
library(tidymodels)
library(visdat)
library(ggplot2)
library(imbalance)
library(readr)
```
# Introduction
This report is dedicated to project of a workshop of master of data science at University of Luxembourg, I built the [`regPackage1`](https://github.com/berserkhmdvhb/regPackage1). 
You can install this package by first installing the [devtools](https://www.r-project.org/nosvn/pandoc/devtools.html) package and then using the following syntax:

`devtools::install_github("https://github.com/berserkhmdvhb/regPackage1")`

You can explore the documentation of package I provided with 

`help(package="regPackage1")`

Also, this report is accessible as vignette of the package, which can be accessed with

`vignette(package = "regPackage1")`

(Note: I just made a meta-reference)


Note that all functions of the package are suffixed with `hmd`.


 
# Load Dataset
To provide a test case on a dataset with discrete target variable, I used the the [car insurance data](https://www.kaggle.com/datasets/sagnik1511/car-insurance-data).

The dataset is embedded in the package, therefore by simply running the following commands one can load and display the dataset.
. It can be used by the following syntax:

`data(car_insurance_data)`




```{r}
data(car_insurance_data)

dplyr::glimpse(car_insurance_data)
```


Summary of statistical properties of columns are provided in the following:

```{r}
summary(car_insurance_data)
```




# Preprocess
Before feeding data to the model, various preprocessing stages are performed in the following subsections:

## Clean Column Names

```{r}
df <- janitor::clean_names(car_insurance_data)

names(df)
```

And the following is to make the codes reproducible, as random values might be involved in different stages:
```{r}
set.seed(12345)
```

## Categorical Columns
We need to factorise the categorical columns, which can be done by merely inputting columns intended to be converted in `cat_cols` in the `prepare_hmd` function. Before doing that, we report and visualise the nature of categorical data and their frequency in the dataset

```{r}
categoricals_print_hmd(df)
```

```{r warning=FALSE}
vis_dat(df)
```

```{r}
df <- categoricals_hmd(df) 
dplyr::glimpse(df)
```


```{r}
vis_dat(df)
```


## Missing Data



```{r}
df[is.na(df) | df=="Inf"] = NA
vis_miss(df, sort_miss = TRUE)
```


```{r}
is.na(df |> select("credit_score","annual_mileage")) |> colSums()
## Classification Models
```

As only two numerical columns include NA values, the will be imputed with the median of their respective columns.
For this `impute_median_hmd` function is used from the package:

```{r}
df <- impute_median_hmd(df)
is.na(df) |> colSums()
```
As evident, there is no missing data anymore.
## Fix Imbalanced Target

### Visualize Balance 

As imbalance of target classes affect predictions, the frequency of each class in the `outcome` column is visualized:


```{r}
# Most basic bar chart
ggplot(df, aes(x = outcome)) +
    geom_bar()
```

```{r}
table(df$outcome)
```

```{r}
imbalance::imbalanceRatio(df, classAttr = "outcome")
```
### Encoding Categorical Columns

Since later it is realized that data is imbalanced and therefore it should be resampled, it is required that data would only contain numerical columns for the next part. For this reason, one-hot-encoding is applied in the following:

```{r}
dummy <- dummyVars(" ~ .", data=df)
df_enc <- data.frame(predict(dummy, newdata = df)) 
dplyr::glimpse(df_enc)

```

Ensuring the encoded dataframe didn't slip a NA value:
```{r}
is.na(df_enc) |> colSums()
```

### Split to Train/Test



```{r}

df_dict <- splitter_norm_hmd(df_enc, 
                             replace=FALSE,
                             proportion=0.7,
                             normalize=FALSE)
train <- df_dict$train
test <- df_dict$test

print("train data has ")
print(paste("train data has", nrow(train), "rows and", ncol(train)), "columns")
print(paste("test data has", nrow(test), "rows and", ncol(test)), "columns")
```

### Oversampling


```{r}
#X <- df_enc[, colnames(df_enc)[colnames(df_enc) != #'outcome']]
#y <- df_enc[['outcome']]

insurance_train <- racog(train, numInstances = 3734, burnin = 100, lag = 20, classAttr = "outcome")

#df_smote <- smotefamily::BLSMOTE(X, y)$syn_data
```


```{r}
table(insurance_train$outcome)
```

```{r}
dplyr::glimpse(insurance_train)
```

#```{r message = FALSE, warning = FALSE, results = #'hide'}
```{r}
#df_smote <- rename(df_smote, outcome = class)
#ggplot(df_smote, aes(x = outcome)) +
#    geom_bar()
```

 
Save the processed dataframe to memory:
```{r}
path = "/home/hamed/Documents/R/regPackage1/inst/"
file_name = "insurance_train.csv"
readr::write_csv(insurance_train, 
                 file = paste(path,file_name,sep=""))


```


Load back the processed data

```{r}
insurance_train <- readr::read_csv(paste(path,file_name,sep=""))
```

Do the same for test data

```{r}
insurance_test <- test
path = "/home/hamed/Documents/R/regPackage1/inst/"
file_name = "insurance_test.csv"
readr::write_csv(insurance_test, 
                 file = paste(path,file_name,sep=""))
```
